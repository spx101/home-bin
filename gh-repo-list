#!/usr/bin/env python3
# -*- encoding: utf-8 -*-
# pylint: disable=missing-function-docstring
# flake8: noqa

import sys
from tabulate import tabulate
import requests
import os
import json
import pickle
from datetime import datetime
import argparse

from rich import box, print, print_json
from rich.console import Console
from rich.table import Table
import yaml

# global_box = box.DOUBLE
# global_box = box.MARKDOWN
# global_box = box.ASCII_DOUBLE_HEAD
global_box = box.ASCII2

ORG = "Ringier-Axel-Springer-PL"
PER_PAGE = 100
CACHE_FILE = os.path.expanduser("~/.cache/gh-repo-list.json")

def read_github_token():
    config_path = os.path.expanduser("~/.config/gh/hosts.yaml")
    if os.path.exists(config_path):
        with open(config_path, "r", encoding="utf-8") as file:
            config = yaml.safe_load(file)
            data = config.get("github.com", {})
            return data.get("oauth_token")
    return user, None

def read_cache(filename, time_min=60):
    # Sprawdzenie, czy plik jest starszy niż 5 minut
    if os.path.exists(filename):
        file_modified_time = os.path.getmtime(filename)
        current_time = datetime.now().timestamp()
        time_difference = current_time - file_modified_time
        if time_difference > (time_min * 60):  # 5 minut w sekundach
            return []
        else:
            if filename.endswith(".json"):
                with open(filename, "r", encoding="utf-8") as json_file:
                    return json.load(json_file)
            else:
                with open(filename, "rb") as file:
                    return pickle.load(file)
    else:
        return []
        # print("Plik nie istnieje.")


def save_cache(filename, datain):
    if filename.endswith(".json"):
        with open(filename, "w", encoding="utf-8") as json_file:
            json.dump(datain, json_file, ensure_ascii=False, indent=4)
    else:
        with open(filename, "wb") as file:
            pickle.dump(datain, file)

def main(args):

    #token = read_github_token()
    token = os.getenv("GITHUB_TOKEN_TOKEN")

    headers = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28",
    }

    if not token:
        print("gh-login spx101")
        exit(1)

    namespaces = []
    if args.namespace:
        namespaces = args.namespace.split(',')

        items = []
        for namespace in namespaces:
            base_url = f"https://api.github.com/search/repositories?q=props.namespace%3A{namespace}+org%3A{ORG}"
            print(f"Pobieram dane z GitHuba, namespace={namespace}", file=sys.stderr)
            page = 1
            while True:
                url = f"{base_url}&page={page}&per_page={PER_PAGE}"
                print(url, file=sys.stderr)
                response = requests.get(url, headers=headers, timeout=10)
                print(f"Strona: {page} {response} items: {len(items)}", file=sys.stderr)

                data = response.json()
                if not data.get("items"):
                    break

                items.extend(data.get("items"))
                page += 1

        id_list = [item["id"] for item in items]
        cached_items = read_cache(CACHE_FILE)
        cached_items = [item for item in cached_items if item["id"] not in id_list]
        cached_items.extend(items)
        with open(CACHE_FILE, "w", encoding="utf-8") as json_file:
            json.dump(cached_items, json_file, ensure_ascii=False, indent=4)

    else:

        base_url = f"https://api.github.com/orgs/{ORG}/repos"
        print("read cache", file=sys.stderr)
        items = [] if args.refresh else read_cache(CACHE_FILE)
        print(f"Number of items in cache: {len(items)}", file=sys.stderr)
        if not items:
            print("Pobieram dane z GitHuba", file=sys.stderr)
            page = 1
            while True:
                url = f"{base_url}?page={page}&per_page=100"
                print(url, file=sys.stderr)
                response = requests.get(url, headers=headers, timeout=10)
                print(f"Strona: {page} {response} items: {len(items)}", file=sys.stderr)
                data = response.json()
                items.extend(data)
                if not data:
                    break
                page += 1
            save_cache(CACHE_FILE, items)

        with open(CACHE_FILE, "w", encoding="utf-8") as json_file:
            json.dump(items, json_file, ensure_ascii=False, indent=4)

    filtered_data = sorted(items, key=lambda x: x["created_at"])

    if args.filter:
        filtered_data = [
            item for item in filtered_data if item["name"].startswith(args.filter)
        ]

    # if args.namespace:
    #     namespaces = args.namespace.split(',')
    #     filtered_data = [
    #         item for item in filtered_data
    #         if any(f"Ringier-Axel-Springer-PL/{ns}" in item["html_url"] for ns in namespaces)
    #     ]

    if args.output == "table":
        print_table(filtered_data)
    elif args.output == "json":
        print_json(data=filtered_data)
    else:
        print("Unknown output format", file=sys.stderr)
    #print(tabulate(sorted_data, headers="keys", tablefmt="csv"))


def print_table(data):
    t = Table(
        title="Repositories",
        box=global_box,
        show_lines=False,
        show_header=True,
        header_style="yellow",
        title_style="magenta",
        highlight=False,
    )
    t.add_column("URL", justify="left", style="cyan", no_wrap=True)
    t.add_column("open_issues_count", style="")
    t.add_column("default_branch", style="")
    t.add_column("created_at", style="")
    t.add_column("topics", style="")

    for item in data:
        t.add_row(
            str(item.get("html_url")),
            str(item.get("open_issues_count")),
            str(item.get("default_branch")),
            str(item.get("created_at")),
            str(",".join(item.get("topics"))),
        )

    console = Console(emoji=False, highlight=False)
    console.print(t)


def usage():
    return """
    pobieranie pull requestów z GitHuba
    """


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description=("Fetching the list of pull requests from GitHub"),
        add_help=True,
        epilog="be happy ;)",
        usage=usage(),
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument("--test", dest="test", help="test", action="store_true")
    parser.add_argument(
        "-r", "--refresh", dest="refresh", help="Refresh", action="store_true"
    )
    parser.add_argument(
        "-n", "--namespace", dest="namespace", help="Namespace comma separated", type=str, default=None
    )
    parser.add_argument(
        "-o", "--output", dest="output", help="Output format", type=str, default="table"
    )
    parser.add_argument(
        "-f", "--filter", dest="filter", help="filter, startswith", type=str
    )
    args = parser.parse_args()
    main(args)
